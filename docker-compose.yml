# Docker Compose for Speech-to-Text Server
#
# Usage:
#   Start:    docker-compose up -d
#   Stop:     docker-compose down
#   Logs:     docker-compose logs -f
#   Rebuild:  docker-compose build --no-cache

version: '3.8'

services:
  speech-to-text:
    build:
      context: ./speech-to-text-server
      dockerfile: Dockerfile
    container_name: speech-to-text-server
    ports:
      - "5000:5000"
    environment:
      # Whisper model configuration
      # Options: tiny, base, small, medium, large-v3
      # Larger models = better accuracy but slower and more memory
      - WHISPER_MODEL=base
      # Device: cpu or cuda (if you have NVIDIA GPU with CUDA)
      - WHISPER_DEVICE=cpu
      # Compute type: int8 (fastest on CPU), float16 (GPU), float32 (most accurate)
      - WHISPER_COMPUTE_TYPE=int8
    volumes:
      # Persist the Whisper model cache to avoid re-downloading
      - whisper-cache:/home/whisper/.cache
    restart: unless-stopped
    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  whisper-cache:
    name: speech-to-text-whisper-cache
